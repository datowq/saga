import React, { useState, useEffect } from "react";
import { Remark } from "react-remark";

// Import language support
import "monaco-editor/esm/vs/basic-languages/javascript/javascript.contribution";
import "monaco-editor/esm/vs/basic-languages/html/html.contribution";
import "monaco-editor/esm/vs/basic-languages/css/css.contribution";

const text = `
# Implementing NPC Interactions using Google Gemini API

Below, you will be able to examine the source code that runs in the background of our little NPC interactions. Together, we will walk through it, so that, by the end of this tutorial, you would be able to implement an NPC conversation on your own.

## Setting up the LLM API

First let's import the necessary React hooks and components, as well as the Google Generative AI module. You can find full Google documentation for Node.js [here](https://ai.google.dev/gemini-api/docs/get-started/node).

We initialize the \`GoogleGenerativeAI\` module using our custom API key that can be generated in Google AI Studio. To avoid leaking it to the public, we save our key in a \`.env\` file and put the file under \`.gitignore\`. Then, we create four different model objects; the first two represent Albert Einstein and J. Robert Oppenheimer, who, as you could see in our demo, were having a conversation together. The third model is LeBron James, who we have talked to in the demo directly. The last model is a recommendation model; the one that was feeding the player responses during the conversation with LeBron James.

\`\`\`javascript
import React, { useEffect, useState, useRef } from "react";
import { Html, Text, Sky } from "@react-three/drei";
import Box from "../components/3d/prefabs/Box";
import Player from "../components/3d/prefabs/Player";
import PlaygroundScene from "../components/3d/scenes/PlaygroundScene";
import { GoogleGenerativeAI } from '@google/generative-ai';

const GOOGLE_API_KEY = import.meta.env.VITE_GOOGLE_API_KEY;

const genAI = new GoogleGenerativeAI(GOOGLE_API_KEY);
const einstein = genAI.getGenerativeModel({ model: 'gemini-pro' });
const oppenheimer = genAI.getGenerativeModel({ model: 'gemini-pro' });
const leBron = genAI.getGenerativeModel({ model: 'gemini-pro' });
const suggest = genAI.getGenerativeModel({ model: 'gemini-pro' });
\`\`\`
Next, let's set up chats for each of the four models. The first directive we give to each model within its \`history\` is very important, as this will usually dictate how it will respond during future interactions.

Note that it's also important to set a high enough number for \`maxOutputTokens\` that can be generated by the model. We faced issues during the implementation of our demo related to low maximum number of tokens that would result in empty responses if the model went over.

\`\`\`javascript
const chatEinstein = einstein.startChat({
  history: [
    {
      role: 'user',
      parts: [{ text: 'Pretend that you are Albert Einstein, a famous theoretical physicist, \nwho developed the theory of relativity. Next message that will be sent to you is from \nanother theoretical physicist, J. Robert Oppenheimer. Discuss the meaning of life with \nOppenheimer. Do not simulate the other person\'s responses. Just act as Einstein. Also do not \noutput your own thoughts. Response with a maximum of two sentences.' }],
    },
    {
      role: 'model',
      parts: [{ text: 'Understood. Ready to talk to Oppenheimer!' }],
    },
  ],
  generationConfig: {
    maxOutputTokens: 500,
  },
});

const chatOppenheimer = oppenheimer.startChat({
  history: [
    {
      role: 'user',
      parts: [{ text: 'Pretend that you are J. Robert Oppenheimer, a famous theoretical physicist, \nwho led the Manhattan Project. Next message that will be sent to you is from another theoretical \nphysicist, Albert Einstein. Discuss the meaning of life with Einstein. Do not simulate the other \nperson\'s responses. Just act as Oppenheimer. Also do not output your own thoughts. Response with \na maximum of two sentences.' }],
    },
    {
      role: 'model',
      parts: [{ text: 'Understood. Ready to talk to Einstein!' }],
    },
  ],
  generationConfig: {
    maxOutputTokens: 500,
  },
});

const chatLeBron = leBron.startChat({
  history: [
    {
      role: 'user',
      parts: [{ text: 'Pretend that you are an NPC representing LeBron James, a famous basketball \nplayer playing for Los Angeles Lakers, who won 4 NBA Championships. Next message that will be sent \nto you is from a player of the game who would like to you about your career. Discuss the importance \nof healthy lifestyle with the player. Do not simulate the other person\'s responses. Just act as \nLeBron. Also do not output your own thoughts. Response with a maximum of two sentences.' }],
    },
    {
      role: 'model',
      parts: [{ text: 'Understood. Ready to talk to an NPC!' }],
    },
  ],
  generationConfig: {
    maxOutputTokens: 500,
  },
});

const suggestions = suggest.startChat({
  history: [
    {
      role: 'user',
      parts: [{ text: 'You are representing a player of the game who is having a conversation \nwith LeBron James, a famous basketball player. For each prompt you receive from LeBron James, \nplease give a very short response, no longer than one sentence. Give very diverse responses. \nYou should act very humble, and seek LeBron\'s advice on sport and life. \nMAX ONE SENTENCE RESPONSES' }],
    },
    {
      role: 'model',
      parts: [{ text: 'Understood. Ready to talk to an NPC!' }],
    },
  ],
  generationConfig: {
    maxOutputTokens: 500,
  },
});
\`\`\`

## Handling states and requests/responses

Handling a conversation between two different models requires complex state handling, since a response from one model must be fed as input to the other, while keeping in mind that most of the code is asynchronous.

First of all, we need to keep track of various states in the game:

\`\`\`javascript
function MLAgent() {
  // keeps track whether the player is currently looking at some NPC
  const [hitObject, setHitObject] = useState("none");
  // display conversation between Einstein and Oppenheimer on screen
  const [showConversationWindow, setConversationWindow] = useState(false);
  // display conversation between LeBron James and the player on screen
  const [showInteractionWindow, setInteractionWindow] = useState(false);

  // holds Einstein's response to the latest message
  const [einsteinResponse, setEinsteinResponse] = useState([]);
  // holds Oppenheimer's response to the latest message
  const [oppenheimerResponse, setOppenheimerResponse] = useState([]);
  // true after conversation between Einstein and Oppenheimer has been started
  const [isConversationStarted, setIsConversationStarted] = useState(false);
  // true if one of the scientists is currently generating their response
  const [isGenerating, setIsGenerating] = useState(false);
  // keeps track which of the two scientists is currently speaking
  const [currentSender, setCurrentSender] = useState('Einstein');

  // holds LeBron's response to the latest message
  const [lebronResponse, setLebronResponse] = useState('');
  // true after interaction between LeBron James and user has been started
  const [isInteractionStarted, setIsInteractionStarted] = useState(false);

  // next 3 states hold responses suggested to the user in conversation with LeBron James
  const [response1, setResponse1] = useState('');
  const [response2, setResponse2] = useState('');
  const [response3, setResponse3] = useState('');
  \`\`\`
  The \`handleSendPrompt\` function handles the submission of a message to the LeBron James model. Notice we use streaming that allows the conversation to be rendered instantaneously, without waiting for the entire result.

  \`\`\`javascript
  const lebronResponseRef = useRef('');

  const handleSendPrompt = async (prompt) => {
    if (prompt.trim() !== '') {
      const result = await chatLeBron.sendMessageStream(prompt);
      lebronResponseRef.current = '';
      for await (const chunk of result.stream) {
        const chunkText = chunk.text();
        lebronResponseRef.current += chunkText;
        setLebronResponse(lebronResponseRef.current);
      }

      const result1 = await suggestions.sendMessage(lebronResponseRef.current);
      const response1 = await result1.response;
      setResponse1(response1.text);

      const result2 = await suggestions.sendMessage(lebronResponseRef.current);
      const response2 = await result2.response;
      setResponse2(response2.text);

      const result3 = await suggestions.sendMessage(lebronResponseRef.current);
      const response3 = await result3.response;
      setResponse3(response3.text);
    }
  };

  \`\`\`
  The \`handleSuggestedResponse\` function below handles the submission of the specified response back to the LeBron James model. Selection of the response is handled by buttons (as shown later!).

  \`\`\`javascript
  const handleSuggestedResponse = (response) => {
    setResponse1('');
    setResponse2('');
    setResponse3('');
    handleSendPrompt(response);
  };
  \`\`\`
  The \`startInteraction\` function is almost identical to \`handleSendPrompt\`; except this function is used to initiate the conversation and thus, it has a pre-defined greeting message.

  \`\`\`javascript
  const startInteraction = async () => {
    setIsInteractionStarted(true);
    const result = await chatLeBron.sendMessageStream('Hello, LeBron James!');
    lebronResponseRef.current = '';
    for await (const chunk of result.stream) {
      const chunkText = chunk.text();
      lebronResponseRef.current += chunkText;
      setLebronResponse(lebronResponseRef.current);
    }

    const result1 = await suggestions.sendMessage(lebronResponseRef.current);
    const response1 = await result1.response;
    setResponse1(response1.text);

    const result2 = await suggestions.sendMessage(lebronResponseRef.current);
    const response2 = await result2.response;
    setResponse2(response2.text);

    const result3 = await suggestions.sendMessage(lebronResponseRef.current);
    const response3 = await result3.response;
    setResponse3(response3.text);
  };
  \`\`\`
  The \`startConversation\` function below initiates conversation between the models of Einstein and Oppenheimer. Notice that we have implemented a check whether the request we're sending is the first one in history of the chat. If so, we start with a pre-defined greeting; otherwise, we accept output from one model and feed it as output to the other.

  \`\`\`javascript
  const einsteinResponseRef = useRef('');
  const oppenheimerResponseRef = useRef('');

  let isFirstMessage = true;

  const startConversation = async () => {
    while (true) {
      setIsGenerating(true);

      setEinsteinResponse([]);
      setOppenheimerResponse([]);

      if (isFirstMessage) {
        const result1 = await chatEinstein.sendMessageStream('Hello Albert!');
        einsteinResponseRef.current = '';
        for await (const chunk of result1.stream) {
          const chunkText = chunk.text();
          einsteinResponseRef.current += chunkText;
          setEinsteinResponse(() => [
            { sender: 'Einstein', message: einsteinResponseRef.current },
          ]);
        }
        isFirstMessage = false;
      } else {
        const result1 = await chatEinstein.sendMessageStream(oppenheimerResponseRef.current);
        einsteinResponseRef.current = '';
        for await (const chunk of result1.stream) {
          const chunkText = chunk.text();
          einsteinResponseRef.current += chunkText;
          setEinsteinResponse(() => [
            { sender: 'Einstein', message: einsteinResponseRef.current },
          ]);
        }
      }

      setCurrentSender('Oppenheimer');

      const result2 = await chatOppenheimer.sendMessageStream(einsteinResponseRef.current);
      oppenheimerResponseRef.current = '';
      for await (const chunk of result2.stream) {
        const chunkText = chunk.text();
        oppenheimerResponseRef.current += chunkText;
        setOppenheimerResponse(() => [
          { sender: 'Oppenheimer', message: oppenheimerResponseRef.current },
        ]);
      }

      setCurrentSender('Einstein');
      setIsGenerating(false);

      // Wait for the button to be pressed to generate new round of conversation
      await new Promise((resolve) => {
        const handleButtonClick = () => {
          resolve();
          window.removeEventListener('click', handleButtonClick);
        };
        window.addEventListener('click', handleButtonClick);
      });
    }
  };

  const handleStartConversation = () => {
    setIsConversationStarted(true);
    startConversation();
  };
  \`\`\`

  The \`useEffect\` below is responsible for handling key presses by the user. More specifically, it checks for the 'L' key, which will initiate conversation between Einstein and Oppenheimer, and the 'I' key, which will initiate interaction with LeBron James.

  \`\`\`javascript
  useEffect(() => {
    const handleKeyPress = (event) => {
      if ((event.key === 'l' || event.key === 'L') && \n(hitObject === "einstein" || hitObject === "oppenheimer")) {
        setConversationWindow(prevShowWindow => !prevShowWindow);
      } else if ((event.key === 'i' || event.key === 'I') && (hitObject === "lebron")) {
        setInteractionWindow(prevShowWindow => !prevShowWindow);
      }
    };
  
    document.addEventListener('keydown', handleKeyPress);
  
    return () => {
      document.removeEventListener('keydown', handleKeyPress);
    };
  }, [hitObject]);
  \`\`\`
  Lastly, the handlers below create functionality for exiting conversations with the NPCs.
  \`\`\`javascript
  const exitConversation = () => {
    setConversationWindow(false);
    setIsConversationStarted(false);
    isFirstMessage = true;
  };

  const exitInteraction = () => {
    setInteractionWindow(false);
    setIsInteractionStarted(false);
  };
\`\`\`

## Rendering everything on screen

This part of the source code handles the rendering of THREE.js objects on the screen, as well as the rendering of pop-up windows that display conversations with the NPCs.

Notice that we use states defined previously to specify what components should be rendered on the screen at a specific time. For example, when \`showConversationWindow\` is true, we know to display the conversation window between Einstein and Oppenheimer. Similarly, when \`showInteractionWindow\` is true, we display the interaction with LeBron James.

\`\`\`javascript
  return (
    <div className="w-full h-full">
      <div className="fixed h-full w-full text-2xl flex justify-center z-50 items-center">
        +
      </div>
      {(hitObject === "einstein" || hitObject === "oppenheimer") && (
        <div className=" fixed h-full w-full flex justify-center z-50 items-end">
          <div className="p-4 m-2 bg-white text-lg rounded-lg translate-y-[-8rem] drop-shadow-lg">
            <span className="font-bold">Press L</span> to listen to Oppenheimer
            and Einstein's conversation!
          </div>
        </div>
      )}
      {hitObject === "lebron" && (
        <div className="fixed h-full w-full flex justify-center z-50 items-end">
          <div className="p-4 m-2 bg-white text-lg rounded-lg translate-y-[-8rem] drop-shadow-lg">
            <span className="font-bold">Press i</span> to interact with LeBron
          </div>
        </div>
      )}
      {showConversationWindow && (
        <div className="fixed inset-8 flex items-center justify-center z-50">
          <div className="bg-white text-black rounded shadow">
            {!isConversationStarted ? (
              <button onClick={handleStartConversation}>
                Listen to their conversation
              </button>
            ) : (
              <div>
                {einsteinResponse.map((message, index) => (
                  <div key={index}>
                    <strong>{message.sender}:</strong> {message.message}
                  </div>
                ))}
                {oppenheimerResponse.map((message, index) => (
                  <div key={index}>
                    <strong>{message.sender}:</strong> {message.message}
                  </div>
                ))}
                {isGenerating ? (
                  <p>{currentSender} is thinking...</p>
                ) : (
                  <div>
                    <button onClick={() => setIsGenerating(true)}>
                      Continue {currentSender}'s response
                    </button>
                    <button onClick={() => exitConversation()}>
                      Exit the conversation
                    </button>
                  </div>
                )}
              </div>
            )}
          </div>
        </div>
      )}
      {showInteractionWindow && (
        <div className="fixed inset-8 flex items-center justify-center z-50">
          <div className="bg-white text-black rounded shadow-lg drop-shadow">
            {!isInteractionStarted ? (
              <button
                onClick={startInteraction}
                className="w-full text-black text-center hover:bg-black hover:text-white \nbg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded"
              >
                <span className="font-bold">Click</span> to greet LeBron!
              </button>
            ) : (
              <div>
                <div>
                  <h2>LeBron:</h2>
                  <p>{lebronResponse}</p>
                </div>
                {response1.length > 0 &&
                  response2.length > 0 &&
                  response3.length > 0 && (
                    <div>
                      <h3>Suggested Responses:</h3>
                      <button
                        onClick={() => handleSuggestedResponse(response1)}
                      >
                        {response1}
                      </button>
                      <button
                        onClick={() => handleSuggestedResponse(response2)}
                      >
                        {response2}
                      </button>
                      <button
                        onClick={() => handleSuggestedResponse(response3)}
                      >
                        {response3}
                      </button>
                    </div>
                  )}
              </div>
            )}
          </div>
        </div>
      )}
      <PlaygroundScene>

        <Box
          text={false}
          position={[-5, 15, -80]}
          args={[80, 10, 50]}
          color="orange"
          name="bigboi"
        >

        </Box>

        <Player
          controls
          position={[0, 5, 0]}
          args={[0.5]}
          color="yellow"
          setHitObject={setHitObject}
        />

        <Box
          position={[12, 2, -14]}
          args={[1, 3.5, 1.3]}
          color="red"
          name="einstein"
        >
          <Text
            position={[12, 4.5, -14]}
            rotation={[0, -Math.PI / 2 - 0.2, 0]}
            fontSize={1}
            color="red"
            name="einstein"
          >
            EINSTEIN
          </Text>
        </Box>

        <Box
          position={[10, 2, -15]}
          args={[1, 3.5, 1.3]}
          color="purple"
          name="oppenheimer"
        >
          <Text
            position={[10, 4.5, -15]}
            rotation={[0, 1, 0]}
            fontSize={1}
            color="purple"
            name="oppenheimer"
          >
            OPPENHEIMER
          </Text>
        </Box>

        <Box
          position={[0, 2.5, -15]}
          args={[2, 5, 2]}
          color="blue"
          name="lebron"
        >
          <Text
            position={[0, 5.6, -15]}
            fontSize={1}
            color="blue"
            name="lebron"
          >
            LEBRON JAMES
          </Text>
        </Box>

        <Sky />
      </PlaygroundScene>
    </div>
  );
}

export default MLAgent;
\`\`\`
`;

const MarkdownBlock = ({ text }) => <Remark>{text}</Remark>;

function Markdown() {
  return (
    <div className="flex gap-16 pb-2">
      <div className="max-w-screen-md mx-auto">
        <MarkdownBlock text={text} />
      </div>
    </div>
  );
}

export default Markdown;
